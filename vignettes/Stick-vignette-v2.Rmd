---
title: "Stickbreaker Vignette v2"
author: "Craig Miller and JT"
date: "December 12, 2016"
output: html_document
---

This document teaches you how to use the Stickbreaker package.

Write an overview paragraph that goes here.

JT: Figure out how to load libraries in a package. I don't think this is the correct way to do it.....No it is not. 

JT: Figure out how to put TOC at top of document.

```{r, echo=TRUE}
  devtools::load_all()  # Load package
  library(nnet)
  library(lattice)
  library(xtable)
```

## I. Basic Analysis

### Data format

The data should be in a text file. If there are $n$ mutations in the dataset, there should be $n$ columns in the file. The first row should be mutation names. The data in the columns are 0/1 to indicate the absence/presence of the mutation. All 0s indicates wild type and should be the first row of data. The last column is the estimated fitness of that genotype. You can see the format of the data below.

### Read in data

JT: Maybe we should make this readCSV instead of based on an R dataset format. 


```{r, echo=TRUE}
  inpath <- system.file("data", package="Stickbreaker")
  data <- read.csv(paste(inpath,"Chou.data.csv",sep="/"))
```

### Fit models

The `fit.models()` function is a wrapper that fits the data to all three models. First, it estimates d and, using this, fits the stickbreaking model. Then it fits the multipicative and additive models. If you want to do this fitting to models individually and better understand what is going on, see the Detailed Features section.

To fit the models, you need to specify a few things. `d.range` specifies the range of possible values for d. If you fitness values are unusually large you may want to change this range. The upper bound is more important. The reason not to set this really large (say to 100 or 1000) is that the stickbreaking model approaches the additive model as d gets large and the coefficients get small. By putting a modest upper bound on stickbreaking, we demand that additivity remains a distinct model.

When the stickbreaking model doesn't fit the data very well or when the data is really noise, the preffered ways to estimate d can fail. Still, we need to fit the stickbrekaing model (albiet poorly) for comparision reason. We do this simply by multiplying the fitness distance between the wildtype and the largest observed fitness by a factor, `d.adj.max`. The default is 1.1. By making it only slightly above one, we ensure that stickbreaking remains distinct from the additive model.

`wts` specifies how to weight single mutations (genotypes on the wildtype background) vs all other genotypes when estimating the coefficients. If the wildtype fitness is know which much greater accuracy than the other genotypes, then the comparisons to it will have lower variance than the other comparisions. The default weighting is `c(2,1)` which indicates to weight the single mutations twice as heavily as all others which corresponds to our assumption that the wildtype fitness is know without error while all other genotypes have the same error.


```{r, echo=TRUE}
  fit.results <- fit.models(data, d.range=c(0.1, 10), d.adj.max=1.1, wts=c(2,1))
```

`fit.models()` returns a list of results (saved here as `fit.results`).  `fit.results$fit.smry` is the most important item. This is a vector of $R^2$ and P-scores--one each from the three models--that summarize model fits and to be used in the next code block. These summary statistics will be used to determine the posterior probability of each. See paper for details about how these fit statistics are calculated. \cr

The other items in the list are details of fit to each model: `$fit.stick`, `$fit.mult` and `$fit.add`. Each of these contains analagous information, itself organized as a list. [[1]] The coefficients (`$u.hats` for stickbreaking, `$s.hats` for multiplicative, and `$w.hats` for additive). [[2]] `$R2`.  [[3]] `$sig.hat` is estimate of $\sigma$. [[4]] `$log.like`.  [[5]] `$regression.results` is itself a list with `$p.vals`, `lm.intercepts` and `lm.slopes` being the linear regression p-values, intercepts, and slopes for each mutation and `P` being the P-score. \cr

### Generate multinomial model and calculate posterior probabilities

After the data has been fit to the three models, we use the summary fit statistics to assign posterior probabilities to the three models. This is done in three steps: (1) simulate data from priors, (2) fit simulated data to multinomical regression and (3) calcualte posterior probabilities.\cr

*Priors etc.:* To simulate data you need to define your priors and the number of replicate datasets to simulate. These are defined at the beginning of the next code block. `coes.prior` is a vector with the lower and upper bounds on the coefficients; `sig.prior` is the lower and upper bound on the $\sigma$. `n.samps.per.mod` is the number of datasets to simulate per model. You may want to initially set this to a small value like 50 or 100 to check things are running and behaving properly. For a final analysis you should increase this number to 1000 or better yet 10000. Be warned that it will take some time to simulate 10000 datasets for each model. `d.range`, `d.adj.max`, and `wts` are discussed above. Finally, use `analysis.name` to assign a unique name so that the simulated fitted data and the multinomial model it leads to are saved with unique identifiers. These files may be of interest (and save you computing time) if you choose to tap into any of the detailed features detailed below.


```{r, echo=TRUE}
  coes.prior <- c(0.05, 0.5)
  sig.prior <- c(0, 0.25)
  n.samps.per.mod <- 25
  d.range <- c(0.1, 10)
  d.adj.max <- 1.1
  wts <- c(2,1)
  analysis.name <- "Test"
    
  posterior.results <- simulate.data.calculate.posteriors(fit.results$fit.smry, data, analysis.name, coes.prior, sig.prior, d.range, d.adj.max, wts, n.samps.per.mod)
```


## II. Detailed Features

### Setup

Whereas above we used wrapper functions to do the entire analysis is just a few commands, here we walk through the various functions in greater deatil.

Read in data. See above for format of data.

```{r}
  inpath <- system.file("data", package="Stickbreaker")
  data <- read.csv(paste(inpath,"Khan.data4.csv",sep="/"))
```

Define parameters to use in estimation (`wts`, `d.range` and `d.adj.max`). Again, these are discussed above. Then extract number of genotypes (`n.genos`), number of mutations (`n.muts`), the genotype matrix (`geno.matrix`; the 0/1 columns in the data) and the fitness matrix (`fit.matrix`; the last column in the data). 

```{r}
  wts <- c(2,1)
  d.range <- c(0.1, 10)
  d.adj.max <- 1.1
  
  n.genos <- length(data[,1])
  n.muts <- length(data[1,])-1
  geno.matrix <- data[,seq(1, n.muts)]
  fit.matrix <- as.matrix(data[,(n.muts+1)])
```

### Model Fitting

#### Fit to Stickbreaking Model
We have two good estimators of the distance to the fitness boundary. We call them using the functions `d.hat.MLE()` and `d.hat.RDB()`. We take the MLE as the estimate unless it fails; in which case we use the RDB estimate. If both fail, we simply use the distance from wild type to the largest observed fitness value adjusted upwards by a factor `d.adj.max`. This is done in `d.hat.seq`. Why adjust the maximum estimate upwards at all?  If we do not, the genotype with maximum fitness is at the boundary which is problematic since it results in a zero in the denominator when estimating d for this genotype. 

```{r}
  d.hat.MLE <- estimate.d.MLE(geno.matrix, fit.matrix, d.range=d.range)
  d.hat.RDB <- estimate.d.RDB(geno.matrix, fit.matrix)$d.hat.RDB
  d.hat.seq <- estimate.d.sequential(geno.matrix, fit.matrix, 
                                     d.hat.MLE, d.hat.RDB, d.range, d.adj.max)
  d.hat.MLE
  d.hat.RDB
  d.hat.seq
```

After getting an estimate for d, we call `fit.stick.model.given.d()`. This returns a list the  with the stickbreaking coefficients (`$u.hats`), $R^2$ (`$R2`), $\hat{\sigma}$ (`$sig.hat`) and the log-likelihood (`$log.like`). \cr

The function also performs a linear regression of background fitness against effect. When data are generated and analyzed under the same model, the slope of this regression line is expected to be zero for each mutation with p-values distributed U(0,1). When the data are generated and analyzed under different models, the regression line is expected to be non-zero. One regression is performed per mutation. In each case we calcualte the p-value under the null (no slope). We then summarize the data across mutations by taking the sum of the logs of the p-values and call this sum the P-score. The more negative the p-score, the stronger the evidence against a model being correct. The regression results are returned under the list item `$regression.results` with the sub-items giving p-values (`$p.vals`), intercepts (`$lm.intercepts`), and slopes (`$lm.slopes`) and the overall P-score (`$P`).\cr

Finally, a matrix is returned (`$pred.matris`) that contains model predcited fitness for each genotypes (appended to the data itself along with error and a binary string that can be useful in producing plots).

```{r}
  fit.stick <- fit.stick.model.given.d(geno.matrix, fit.matrix, d.hat.seq, run.regression=TRUE)
  fit.stick
```


#### Fit dataset to multiplicative model

Here we fit to the multiplicative model using `fit.mult.model()`. The output is exactly analagous to that returned from `fit.stick.model()` discussed above except the coefficients are named `$s.hats` (instead of `u.hats`).
```{r}
  fit.mult <- fit.mult.model(geno.matrix, fit.matrix, wts=wts)
  fit.mult
```


#### Fit dataset to additive model

And finally we fit the additive model using `fit.add.model()`. Again the outputs are the same except coefficients are `$w.hats`.

```{r}
  fit.add <- fit.add.model(geno.matrix, fit.matrix, wts=wts)
  fit.add
```

